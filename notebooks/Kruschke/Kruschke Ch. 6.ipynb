{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binomial example in depth\n",
    "\n",
    "Most alaposabban megnézzük újra a binomial példát. Érme, vagy bármi, aminek két mutually exclusive kimenetele van  \n",
    "\n",
    " $p(y|\\theta)=\\theta^y(1-\\theta)^{(1-y)}$, ahol  $y \\in Y, Y = \\{0,1\\}$.  \n",
    "   \n",
    " Ez egy trükkös képlet, mert tekinthetünk rá úgy h $\\theta$ fixed, és akkor azt jelenti, amit eddig gondoltunk, hogy bizony ezek a valószínűségek jellemzik a lehetséges kimeneteleket.  \n",
    " Vagy tekinthetünk rá úgy is, hogy y fixed, és legyen az bármi, $\\theta$ változik. Ebben az esetben őt likelihood function-nek nevezzük, és arról szól, hogy bizonyos $\\theta$ értékek mellett mi a valószínűsége az adott, rögzített y bekövetkezésének/megfigyelésének.  \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood function $p(D|\\theta)$\n",
    "A likelihood nem egy valószínűségi eloszlás! Nem vonatkoznak rá ugynazok a megkötések. Értékei ugyan 0 és 1 között lesznek, mert valószínűsg értékeket fejeznek ki, de nem 1 az összeg/integrál.\n",
    "  Várj: biztos h 0 és 1 közt vannak? a ha folytonos, akkor is? (szerintem igen, mert nem az integrálja vagy a deriváltja értdekel, hanem az értéke - szerintem)\n",
    "\n",
    "\"In Bayesian inference, the function p(y|θ) is usually thought of with the data, y,\n",
    "known and fixed, and the parameter, θ, uncertain and variable. Therefore, p(y|θ) is\n",
    "usually called the likelihood function for θ, and Equation 6.2 is called the Bernoulli\n",
    "likelihood function. Don’t forget, however, that the very same formula is also the probability\n",
    "of the datum, y, and can be called the Bernoulli distribution if θ is considered to be fixed\n",
    "and y is thought of as the variable.\"  \n",
    "  \n",
    "We assume that the outcomes are independent of each other, which means that the probability of\n",
    "the set of outcomes is the multiplicative product of the probabilities of the individual outcomes.\n",
    "If we denote the number of heads as $z = \\sum_{i}y_i$ and the number of tails as\n",
    "$N − z = \\sum_{i} (1 − y_i)$, then:  \n",
    "  \n",
    " \n",
    "$p(\\{y i \\}|θ) = \\prod_{i} p(y_i |θ)$ by assumption of independence  \n",
    "\n",
    "$= \\prod_{i}^{y_i}(1-θ)^{1-y_i}$  \n",
    "\n",
    "$=θ^{\\sum_{i}y_i}(1-θ)^{\\sum_{i}1-y_i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beta distributions\n",
    "- it is a probability distribution that we can use as conjugate prior to our likelihood function with the bernoulli coinflip example.\n",
    "- it is defined similar to bernoulli. but not quite the same\n",
    "- it has two shape parameters a and b (analog to heads and tails)\n",
    "- it has a normalizing factor called the beta distribution, which is the function of a and b, but not \\theta as it is integrated out.\n",
    "- https://en.wikipedia.org/wiki/Beta_distribution \n",
    "- mean, mode, and concentration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
